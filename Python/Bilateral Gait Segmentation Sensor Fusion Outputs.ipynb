{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy.io as sio\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib notebook\n",
    "\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold, LeaveOneOut\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Palatino Linotype']\n",
    "rcParams['font.size'] = 18\n",
    "rcParams['figure.autolayout'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_all_files(filedirectory, numfiles):\n",
    "# Get data from .mat files\n",
    "# Assumes input data are in the format of time (rows) x channels (columns)\n",
    "    if len(numfiles) == 0: # numfiles = []\n",
    "        numfiles_start = 0\n",
    "        numfiles_end = len(os.listdir(filedirectory + '\\\\IMU Segmented')) # Use all files in directory\n",
    "        print('Loading {} processed data file(s) ...'.format(numfiles_end - numfiles_start))     \n",
    "    else:\n",
    "        numfiles_start = numfiles[0]\n",
    "        numfiles_end = numfiles[1]\n",
    "        print('Loading {} processed data file(s) ...'.format(numfiles_end - numfiles_start))      \n",
    "\n",
    "    filedict = {}\n",
    "    allindtrigsdict = {}\n",
    "    for fileindex, filename in enumerate(sorted(os.listdir(filedirectory + '\\\\IMU Segmented'))):\n",
    "        if numfiles_start <= fileindex < numfiles_end:\n",
    "            print('=== {} ==='.format(filename))\n",
    "\n",
    "            imu_mat_contents = sio.loadmat(filedirectory + '\\\\IMU Segmented\\\\' + filename)\n",
    "            daqdata = imu_mat_contents['IMU_data_mat']\n",
    "            # Remove channels associated with shank/thigh orientation estimates using acc/gyro only\n",
    "            chans = daqdata[:,np.setdiff1d(np.arange(36),np.array([6,7,15,16,24,25,33,34]))]\n",
    "            \n",
    "            cam_mat_contents = sio.loadmat(filedirectory + '\\\\Camera Features\\\\' + filename[:-13] + 'Combined')                \n",
    "            Lcam = cam_mat_contents['CFEAT_all'][:,9] # Only use shank angle          \n",
    "            Rcam = cam_mat_contents['IFEAT_all'][:,0] # Only use ground angle      \n",
    "\n",
    "            L_trig, R_trig, L_stance, R_stance = daqdata[:,36], daqdata[:,37], daqdata[:,38], daqdata[:,39]\n",
    "\n",
    "            # Define valid triggers (4-digit)\n",
    "            hc_sm_trigs = [1311,1321,1331,1341,1351,2311,2321,3311,3331,4311,4341,5311,5351]\n",
    "            to_sm_trigs = [1112,1122,1132,1142,1152,2112,2122,3112,3132,4112,4142,5112,5152]\n",
    "\n",
    "            L_trig_diff = np.diff(L_trig)\n",
    "            L_trig_ind = np.where(L_trig_diff > 0)[0] + 1\n",
    "            R_trig_diff = np.diff(R_trig)\n",
    "            R_trig_ind = np.where(R_trig_diff > 0)[0] + 1\n",
    "\n",
    "            lhc_ind, lto_ind, rhc_ind, rto_ind = [], [], [], []\n",
    "            lhc_trig, lto_trig, rhc_trig, rto_trig = [], [], [], []\n",
    "\n",
    "            for i in np.arange(len(L_trig_ind)):\n",
    "                if L_trig[L_trig_ind[i]] in hc_sm_trigs:\n",
    "                    lhc_ind.append(int(L_trig_ind[i]))\n",
    "                    lhc_trig.append(int(L_trig[L_trig_ind[i]]))\n",
    "                elif L_trig[L_trig_ind[i]] in to_sm_trigs:\n",
    "                    lto_ind.append(int(L_trig_ind[i]))\n",
    "                    lto_trig.append(int(L_trig[L_trig_ind[i]]))\n",
    "\n",
    "            for i in np.arange(len(R_trig_ind)):\n",
    "                if R_trig[R_trig_ind[i]] in hc_sm_trigs:\n",
    "                    rhc_ind.append(int(R_trig_ind[i]))\n",
    "                    rhc_trig.append(int(R_trig[R_trig_ind[i]]))\n",
    "                elif R_trig[R_trig_ind[i]] in to_sm_trigs:\n",
    "                    rto_ind.append(int(R_trig_ind[i]))\n",
    "                    rto_trig.append(int(R_trig[R_trig_ind[i]]))\n",
    "\n",
    "            lhc_ind, lhc_trig = np.array(lhc_ind), np.array(lhc_trig)\n",
    "            lto_ind, lto_trig = np.array(lto_ind), np.array(lto_trig)\n",
    "            rhc_ind, rhc_trig = np.array(rhc_ind), np.array(rhc_trig)\n",
    "            rto_ind, rto_trig = np.array(rto_ind), np.array(rto_trig)            \n",
    "\n",
    "            # Save the post-processed data and indices/triggers into dictionaries\n",
    "            filedict[filename[:-14]] = [chans,Lcam,Rcam,L_trig,R_trig,L_stance,R_stance]\n",
    "            allindtrigsdict[filename[:-14]] = {'LHC': np.vstack((lhc_ind,lhc_trig)).T, \n",
    "                                         'LTO': np.vstack((lto_ind,lto_trig)).T,\n",
    "                                         'RHC': np.vstack((rhc_ind,rhc_trig)).T, \n",
    "                                         'RTO': np.vstack((rto_ind,rto_trig)).T}\n",
    "    \n",
    "    print('Finished!')\n",
    "    return filedict, allindtrigsdict\n",
    "\n",
    "\n",
    "def unpack_files(filedict, allindtrigsdict, filekeys, arginput):    \n",
    "    # Unpack the list of arguments (arginput)\n",
    "    # Windowing parameters\n",
    "    TRAIN_SIZE = arginput[0] # Sliding window length\n",
    "    PRED_SIZE = arginput[1] # Length of window (after the training window) to get the ground truth label\n",
    "    STEP_SIZE = arginput[2] # Sliding window increment\n",
    "    CHAN_MECH = arginput[3]\n",
    "    PRINT_SUMMARY = arginput[4]\n",
    "    \n",
    "    alldict = {}\n",
    "    alldict['Combined'] = [[],[],[],[],[]]\n",
    "    alldict['Combined File Index'] = []\n",
    "        \n",
    "    for gaitevent in ['LHC','LTO','RHC','RTO']:\n",
    "        alldict['Combined ' + gaitevent + ' Features'] = []\n",
    "        alldict['Combined ' + gaitevent + ' Triggers'] = [] \n",
    "        alldict['Combined ' + gaitevent + ' Augmented'] = []\n",
    "        alldict['Combined ' + gaitevent + ' File Index'] = []\n",
    "        \n",
    "    for fkeyind, fkey in enumerate(filekeys):\n",
    "        print('Preparing file {}: {} ...'.format(fkeyind+1,fkey))\n",
    "        \n",
    "        imudata = filedict[fkey][0]\n",
    "        Lcam = filedict[fkey][1]\n",
    "        Rcam = filedict[fkey][2]\n",
    "        camdata = np.column_stack((Lcam,Rcam))  \n",
    "        alldata = np.column_stack((imudata,camdata))\n",
    "        L_stance = filedict[fkey][5]\n",
    "        R_stance = filedict[fkey][6]\n",
    "        indtrigs = allindtrigsdict[fkey]\n",
    "\n",
    "        _, Xwin, Xfeats, Y1, Y2, win_end = slide_windows(alldata, L_stance, R_stance, TRAIN_SIZE, PRED_SIZE, STEP_SIZE, CHAN_MECH)\n",
    "        alleventdict = event_windows(indtrigs, alldata, CHAN_MECH, TRAIN_SIZE)\n",
    "        \n",
    "        alleventfeats = {'LHC': alleventdict['LHC'][0], \n",
    "                         'LTO': alleventdict['LTO'][0],\n",
    "                         'RHC': alleventdict['RHC'][0], \n",
    "                         'RTO': alleventdict['RTO'][0]}\n",
    "\n",
    "        # Save the sliding windows, their extracted features, ground truth labels, and file indices\n",
    "        alldict['Combined'][0].append(Xwin)\n",
    "        alldict['Combined'][1].append(Xfeats)     \n",
    "        alldict['Combined'][2].append(Y1)\n",
    "        alldict['Combined'][3].append(Y2)\n",
    "        alldict['Combined'][4].append(win_end)\n",
    "        alldict['Combined File Index'].append(np.tile(fkeyind,len(Y1)))\n",
    "\n",
    "        for gaitevent in ['LHC', 'LTO', 'RHC', 'RTO']:\n",
    "            # Save the features extracted from each gait event\n",
    "            alldict['Combined ' + gaitevent + ' Features'].append(alleventfeats[gaitevent])\n",
    "            # Save the trigger associated with each gait event\n",
    "            alldict['Combined ' + gaitevent + ' Triggers'].append(alleventdict[gaitevent][1])\n",
    "            # Save file index associated with each gait event\n",
    "            alldict['Combined ' + gaitevent + ' File Index'].append(np.tile(fkeyind,len(alleventdict[gaitevent][1])))\n",
    "        \n",
    "    # Convert from list to array\n",
    "    alldict['Combined'][0] = np.concatenate(alldict['Combined'][0])\n",
    "    alldict['Combined'][1] = np.concatenate(alldict['Combined'][1])\n",
    "    alldict['Combined'][2] = np.concatenate(alldict['Combined'][2])\n",
    "    alldict['Combined'][3] = np.concatenate(alldict['Combined'][3])\n",
    "    alldict['Combined'][4] = np.concatenate(alldict['Combined'][4])\n",
    "    alldict['Combined File Index'] = np.concatenate(alldict['Combined File Index'])\n",
    "    \n",
    "    for gaitevent in ['LHC', 'LTO', 'RHC', 'RTO']:\n",
    "        # Remove empty lists\n",
    "        alldict['Combined ' + gaitevent + ' Features'] = [features for features in alldict['Combined ' + gaitevent + ' Features'] if len(features) > 0]\n",
    "        alldict['Combined ' + gaitevent + ' Triggers'] = [triggers for triggers in alldict['Combined ' + gaitevent + ' Triggers'] if len(triggers) > 0]\n",
    "        alldict['Combined ' + gaitevent + ' File Index'] = [fileinds for fileinds in alldict['Combined ' + gaitevent + ' File Index'] if len(fileinds) > 0]\n",
    "        \n",
    "        alldict['Combined ' + gaitevent + ' Features'] = np.concatenate(alldict['Combined ' + gaitevent + ' Features'])\n",
    "        alldict['Combined ' + gaitevent + ' Triggers'] = np.concatenate(alldict['Combined ' + gaitevent + ' Triggers'])\n",
    "        alldict['Combined ' + gaitevent + ' File Index'] = np.concatenate(alldict['Combined ' + gaitevent + ' File Index'])\n",
    "        \n",
    "    if PRINT_SUMMARY:\n",
    "        print('\\nAggregated input dimensions: {}'.format(alldict['Combined'][0].shape))\n",
    "        print('Aggregated feature dimensions: {}'.format(alldict['Combined'][1].shape))\n",
    "        print('Aggregated target 1 dimensions: {}'.format(alldict['Combined'][2].shape))\n",
    "        print('Aggregated target 2 dimensions: {}'.format(alldict['Combined'][3].shape))\n",
    "        print('Aggregated win end dimensions: {}'.format(alldict['Combined'][4].shape))\n",
    "        print('\\nAggregated LHC feature dimensions: {}'.format(alldict['Combined LHC Features'].shape))\n",
    "        print('Aggregated LTO feature dimensions: {}'.format(alldict['Combined LTO Features'].shape))\n",
    "        print('Aggregated RHC feature dimensions: {}'.format(alldict['Combined RHC Features'].shape))\n",
    "        print('Aggregated RTO feature dimensions: {}'.format(alldict['Combined RTO Features'].shape))\n",
    "    \n",
    "    return alldict\n",
    "\n",
    "\n",
    "def getmechfeats(X,chanmech):    \n",
    "    X_mech = X[:,chanmech]\n",
    "\n",
    "    X_min = np.min(X_mech,axis=0) \n",
    "    X_max = np.max(X_mech,axis=0)\n",
    "    X_mean = np.mean(X_mech,axis=0)\n",
    "    X_std = np.std(X_mech,axis=0)\n",
    "    X_init = X_mech[0]\n",
    "    X_final = X_mech[-1]\n",
    "\n",
    "    mechfeats = np.array([X_min,X_max,X_init,X_final,X_mean,X_std]).flatten()\n",
    "\n",
    "    return mechfeats\n",
    "\n",
    "\n",
    "def slide_windows(data, target1, target2, train, predict, step, chanmech):\n",
    "# Get data from sliding windows from the beginning to end of the file \n",
    "# train = size of training window\n",
    "# predict = size of forecasting window\n",
    "# step = window increment\n",
    "\n",
    "    X, Y1, Y2 = [], [], []\n",
    "    win_end = []\n",
    "    allfeats = []\n",
    "    \n",
    "    # Form sliding windows from start to end of the data file\n",
    "    for i in range(0, len(data), step):\n",
    "        if i >= train and i < (len(data) - predict):                        \n",
    "            x_i = data[i-train:i]            \n",
    "            if predict > 0:\n",
    "                y1_i = stats.mode(target1[i:i+predict])[0]\n",
    "                y2_i = stats.mode(target2[i:i+predict])[0]\n",
    "                win_end.append(i+predict)\n",
    "            else:\n",
    "                y1_i = stats.mode(target1[i-train:i])[0]\n",
    "                y2_i = stats.mode(target2[i-train:i])[0]                    \n",
    "                win_end.append(i)\n",
    "            \n",
    "            feats = getmechfeats(x_i,chanmech)\n",
    "            allfeats.append(feats)\n",
    "    \n",
    "            X.append(x_i)\n",
    "            Y1.append(y1_i)\n",
    "            Y2.append(y2_i)\n",
    "            \n",
    "    X = np.array(X)\n",
    "    Y1 = np.array(Y1)\n",
    "    Y2 = np.array(Y2)\n",
    "    win_end = np.array(win_end)\n",
    "    \n",
    "    return data, X, allfeats, Y1, Y2, win_end\n",
    "\n",
    "\n",
    "def event_windows(indtrigs, data, chanmech, train_window):\n",
    "# Get data from windows near gait events specified by indtrigs\n",
    "# Try different sized windows (pre_stance before stance and pre_swing before swing)\n",
    "# Try data augmentation (get aug_windows_per_event extra windows beginning aug_pre before to aug_post after the gait event)\n",
    "# scale = normalize data (boolean)\n",
    "    \n",
    "    eventkeys = list(indtrigs.keys())\n",
    "    \n",
    "    alleventdict = {}\n",
    "        \n",
    "    for eventkeyind, eventkey in enumerate(eventkeys):\n",
    "        allfeats, trig_list = [], []\n",
    "\n",
    "        if len(indtrigs[eventkey]) > 0:\n",
    "            inds = indtrigs[eventkey][:,0]\n",
    "            trigs = indtrigs[eventkey][:,1]\n",
    "\n",
    "            # Remove triggers occurring less than 300 ms into DAQ file\n",
    "            keepinds = [inds > train_window]\n",
    "            inds = inds[keepinds]\n",
    "            trigs = trigs[keepinds] \n",
    "\n",
    "            if len(inds) > 0:\n",
    "                for i in range(inds.shape[0]): # Iterates over indices\n",
    "                    x_i = data[inds[i]-train_window:inds[i],:]\n",
    "                    y_i = trigs[i]\n",
    "\n",
    "                    feats = getmechfeats(x_i[-train_window:],chanmech)\n",
    "\n",
    "                    allfeats.append(feats)\n",
    "                    trig_list.append(y_i)\n",
    "\n",
    "                # Convert from list of arrays to 3D array        \n",
    "                alleventdict[eventkey] = [np.array(allfeats)] # Extracted features\n",
    "                alleventdict[eventkey].append(np.array(trig_list)) # Target\n",
    "        else:\n",
    "            alleventdict[eventkey] = [[],[]]\n",
    "    \n",
    "    return alleventdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segmentation(alldict,filedict,filekeys,allindtrigsdict,trainfiles,testfiles,trainwin,USE_FEAT,pcaprop):\n",
    "    LR = linear_model.LogisticRegression()\n",
    "    RF = RandomForestClassifier()\n",
    "    LDA = LinearDiscriminantAnalysis()\n",
    "    SVM = SVC(probability = True)\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    pca = PCA(n_components = pcaprop)\n",
    "    \n",
    "    allfiles = alldict['Combined File Index']\n",
    "    allwins = alldict['Combined'][0]\n",
    "    allfeats = alldict['Combined'][1]\n",
    "    L_truth = alldict['Combined'][2]\n",
    "    R_truth = alldict['Combined'][3]\n",
    "    allwinend = alldict['Combined'][4]    \n",
    "    \n",
    "    for testind, testfile in enumerate(testfiles):\n",
    "        print('=== Testing on {} ==='.format(filekeys[testfile]))\n",
    "        \n",
    "        trainingfiles = np.setdiff1d(np.unique(trainfiles),testfile)\n",
    "        testwin_ind = [i for i in range(len(allfiles)) if allfiles[i] in [testfile]]\n",
    "        trainwin_ind = [i for i in range(len(allfiles)) if allfiles[i] in trainingfiles]\n",
    "    \n",
    "        testfeat_imu = allfeats[testwin_ind][:,USE_FEAT]\n",
    "        testwin_Lcam, testwin_Rcam = allwins[testwin_ind][:,:,28], allwins[testwin_ind][:,:,29]\n",
    "        testtruth_L, testtruth_R = L_truth[testwin_ind], R_truth[testwin_ind]\n",
    "        \n",
    "        trainfeat_imu = allfeats[trainwin_ind][:,USE_FEAT]\n",
    "        trainwin_Lcam, trainwin_Rcam = allwins[trainwin_ind][:,:,28], allwins[trainwin_ind][:,:,29]\n",
    "        traintruth_L, traintruth_R = L_truth[trainwin_ind], R_truth[trainwin_ind]\n",
    "        \n",
    "        # Scale features\n",
    "        scaler.fit(trainfeat_imu)\n",
    "        trainfeats_scale = scaler.transform(trainfeat_imu)\n",
    "        testfeats_scale = scaler.transform(testfeat_imu)\n",
    "\n",
    "        # Dim. red. features\n",
    "        pca.fit(trainfeats_scale)\n",
    "        train_red = pca.transform(trainfeats_scale)\n",
    "        test_red = pca.transform(testfeats_scale)\n",
    "        \n",
    "        IMU_prob = []\n",
    "        # Train and test for R/L legs (outputs probability of stance)\n",
    "        for traintruth in [traintruth_L.ravel(), traintruth_R.ravel()]:\n",
    "            LR_prob = LR.fit(train_red,traintruth).predict_proba(test_red)\n",
    "            RF_prob = RF.fit(trainfeats_scale,traintruth).predict_proba(testfeats_scale)\n",
    "            LDA_prob = LDA.fit(train_red,traintruth).predict_proba(test_red)\n",
    "            SVM_prob = SVM.fit(train_red,traintruth).predict_proba(test_red)\n",
    "            \n",
    "            IMU_prob.append(LR_prob)\n",
    "            IMU_prob.append(RF_prob)\n",
    "            IMU_prob.append(LDA_prob)\n",
    "            IMU_prob.append(SVM_prob)\n",
    "\n",
    "        # IMU_prob = [LR_Lprob, RF_Lprob, LDA_Lprob, SVM_Lprob, LR_Rprob, RF_Rprob, LDA_Rprob, SVM_Rprob]\n",
    "        \n",
    "        # Make templates for RTO and LHC events\n",
    "        RTO_templates = []\n",
    "        LHC_templates = []\n",
    "        # Get all the RTO and LHC templates from the training files and average        \n",
    "        for trainfile in trainingfiles:  \n",
    "            RTOinds = np.array(allindtrigsdict[filekeys[trainfile]]['RTO'][:,0])\n",
    "            RTOinds = RTOinds[1:-1] # Remove non-steady-state steps\n",
    "            LHCinds = np.array(allindtrigsdict[filekeys[trainfile]]['LHC'][:,0])\n",
    "            LHCinds = LHCinds[1:-1] # Remove non-steady-state steps\n",
    "            for rto in RTOinds:\n",
    "                RTO_temp = filedict[filekeys[trainfile]][2][(rto-trainwin):rto]\n",
    "                RTO_templates.append(RTO_temp)\n",
    "            for lhc in LHCinds:\n",
    "                LHC_temp = filedict[filekeys[trainfile]][1][(lhc-trainwin):lhc] \n",
    "                LHC_templates.append(LHC_temp)        \n",
    "            \n",
    "            RTO_avg_template = sum(RTO_templates)/len(RTO_templates)\n",
    "            LHC_avg_template = sum(LHC_templates)/len(LHC_templates)\n",
    "    \n",
    "        # Get probability for RTO and LHC events based on template matching\n",
    "        Lcamprob = []\n",
    "        Lcambinwin = []\n",
    "        for testwin in range(testwin_Lcam.shape[0]):\n",
    "            cambin = camfeat_bin(LHC_avg_template,testwin_Lcam[testwin,:])\n",
    "            camprob=np.mean(cambin)\n",
    "            Lcamprob.append(camprob)    \n",
    "            Lcambinwin.append(cambin)\n",
    "\n",
    "        Rcamprob = []\n",
    "        Rcambinwin = []\n",
    "        for testwin in range(testwin_Rcam.shape[0]):\n",
    "            cambin = camfeat_bin(RTO_avg_template,testwin_Rcam[testwin,:])\n",
    "            camprob=np.mean(cambin)\n",
    "            Rcamprob.append(camprob)\n",
    "            Rcambinwin.append(cambin)\n",
    "            \n",
    "    return RTO_templates, LHC_templates, testwin_Rcam, testwin_Lcam, IMU_prob, Lcamprob, Lcambinwin, Rcamprob, Rcambinwin, testtruth_L, testtruth_R\n",
    "\n",
    "\n",
    "def camfeat_bin(template, testwindow):\n",
    "    camfeat_product = np.multiply(testwindow,template) # Will be positive whenever the signs match between template and test\n",
    "    cambin = np.zeros_like(camfeat_product)    \n",
    "    for i in range(len(cambin)):\n",
    "        if camfeat_product[i] > 0:\n",
    "            cambin[i]=1\n",
    "\n",
    "    return cambin\n",
    "\n",
    "\n",
    "def calc_resids(gtruth,imupred,campred,fusepred,event,winc):\n",
    "    gtruth_hc = np.where(np.diff(gtruth) == 1)[0] + 1\n",
    "    gtruth_to = np.where(np.diff(gtruth) == -1)[0] + 1\n",
    "    first_hc = np.min(gtruth_hc)\n",
    "    last_to = np.max(gtruth_to)\n",
    "    \n",
    "    if event == 'LHC':\n",
    "        gtruth_event = gtruth_hc\n",
    "        imu_eventpred = np.where(np.diff(imupred) == 1)[0] + 1\n",
    "        cam_eventpred = ((np.where(np.diff(campred) == 1)[0] + 1) + (np.where(np.diff(campred) == -1)[0] + 1))/2\n",
    "        fuse_eventpred = np.where(np.diff(fusepred) == 1)[0] + 1\n",
    "    else:\n",
    "        gtruth_event = gtruth_to\n",
    "        imu_eventpred = np.where(np.diff(imupred) == -1)[0] + 1\n",
    "        cam_eventpred = np.where(np.diff(campred) == -1)[0] + 1\n",
    "        fuse_eventpred = np.where(np.diff(fusepred) == 1)[0] + 1\n",
    "    \n",
    "    # Eliminate unpaired gait events\n",
    "    gtruth_event = [i for i in gtruth_event if i > first_hc and i < last_to]\n",
    "    imu_eventpred = [i for i in imu_eventpred if i > first_hc and i < last_to]\n",
    "    cam_eventpred = [i for i in cam_eventpred if i > first_hc and i < last_to]\n",
    "    fuse_eventpred = [i for i in fuse_eventpred if i > first_hc and i < last_to]\n",
    "    \n",
    "    f1_imu = f1score(gtruth_event,imu_eventpred,5)\n",
    "    f1_cam = f1score(gtruth_event,cam_eventpred,5)\n",
    "    f1_fused = f1score(gtruth_event,fuse_eventpred,5)\n",
    "    \n",
    "    print('GTRUTH: {}'.format(gtruth_event))\n",
    "    print('IMU PRED: {}'.format(imu_eventpred))\n",
    "    print('CAM PRED: {}'.format(cam_eventpred))\n",
    "    print('FUSE PRED: {}'.format(fuse_eventpred))\n",
    "    \n",
    "    imu_resid, cam_resid, fuse_resid = [], [], []\n",
    "    \n",
    "    if len(gtruth_event) > 0:\n",
    "        for true_event in gtruth_event:\n",
    "            all_imu_resid = true_event - imu_eventpred\n",
    "            all_cam_resid = true_event - cam_eventpred\n",
    "            all_fuse_resid = true_event - fuse_eventpred\n",
    "            imu_resid.append(all_imu_resid[np.argmin(abs(all_imu_resid))])\n",
    "            cam_resid.append(all_cam_resid[np.argmin(abs(all_cam_resid))])\n",
    "            fuse_resid.append(all_fuse_resid[np.argmin(abs(all_fuse_resid))])\n",
    "        imu_resid = -winc*np.array(imu_resid)\n",
    "        cam_resid = -winc*np.array(cam_resid)\n",
    "        fuse_resid = -winc*np.array(fuse_resid)\n",
    "        \n",
    "    return imu_resid, cam_resid, fuse_resid, f1_imu, f1_cam, f1_fused\n",
    "\n",
    "\n",
    "def f1score(true,pred,tol):\n",
    "    tp, fn = 0, 0\n",
    "    for event in np.array(true):\n",
    "        if np.min(abs(event - np.array(pred))) <= tol:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    if len(pred) > len(true):\n",
    "        fp = len(pred) - len(true)\n",
    "    else:\n",
    "        fp = 0\n",
    "    \n",
    "    f1score = (2.*tp)/(2.*tp + fn + fp)\n",
    "    \n",
    "    return [tp, fn, fp, f1score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files and organize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 14 processed data file(s) ...\n",
      "=== LW_001_processed.mat ===\n",
      "=== LW_002_processed.mat ===\n",
      "=== LW_003_processed.mat ===\n",
      "=== LW_004_processed.mat ===\n",
      "=== LW_005_processed.mat ===\n",
      "=== LW_006_processed.mat ===\n",
      "=== LW_obstructed_001_processed.mat ===\n",
      "=== LW_obstructed_002_processed.mat ===\n",
      "=== LW_obstructed_003_processed.mat ===\n",
      "=== LW_obstructed_004_processed.mat ===\n",
      "=== LW_obstructed_005_processed.mat ===\n",
      "=== LW_obstructed_turn_001_processed.mat ===\n",
      "=== LW_obstructed_turn_002_processed.mat ===\n",
      "=== LW_obstructed_turn_004_processed.mat ===\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "FILEDIR = u'C:\\\\Users\\\\bhu\\\\Git\\\\Bilateral_Gait_Segmentation\\\\Data'\n",
    "NUM_FILES = [] # if empty list, load all files; otherwise [X] means load X files\n",
    "filedict, allindtrigsdict = load_all_files(FILEDIR, NUM_FILES)\n",
    "filekeys = sorted(list(filedict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing file 1: LW_001 ...\n",
      "Preparing file 2: LW_002 ...\n",
      "Preparing file 3: LW_003 ...\n",
      "Preparing file 4: LW_004 ...\n",
      "Preparing file 5: LW_005 ...\n",
      "Preparing file 6: LW_006 ...\n",
      "Preparing file 7: LW_obstructed_001 ...\n",
      "Preparing file 8: LW_obstructed_002 ...\n",
      "Preparing file 9: LW_obstructed_003 ...\n",
      "Preparing file 10: LW_obstructed_004 ...\n",
      "Preparing file 11: LW_obstructed_005 ...\n",
      "Preparing file 12: LW_obstructed_turn_001 ...\n",
      "Preparing file 13: LW_obstructed_turn_002 ...\n",
      "Preparing file 14: LW_obstructed_turn_004 ...\n",
      "\n",
      "Aggregated input dimensions: (5253L, 150L, 30L)\n",
      "Aggregated feature dimensions: (5253L, 180L)\n",
      "Aggregated target 1 dimensions: (5253L, 1L)\n",
      "Aggregated target 2 dimensions: (5253L, 1L)\n",
      "Aggregated win end dimensions: (5253L,)\n",
      "\n",
      "Aggregated LHC feature dimensions: (85L, 180L)\n",
      "Aggregated LTO feature dimensions: (86L, 180L)\n",
      "Aggregated RHC feature dimensions: (82L, 180L)\n",
      "Aggregated RTO feature dimensions: (83L, 180L)\n"
     ]
    }
   ],
   "source": [
    "FS = 500. # Sampling rate is 500 Hz\n",
    "TRAIN_MS = 300. # Sliding windows are 300 ms long\n",
    "TRAIN_SIZE = int((TRAIN_MS/1000)/(1/FS))\n",
    "PRED_MS = 0 # Prediction windows are 0 ms after the end of the sliding window (i.e. the last time step)\n",
    "PRED_SIZE = int((PRED_MS/1000.)/(1/FS)) # Prediction is the current time step\n",
    "STEP_MS = 30. # The window increment is 30 ms\n",
    "STEP_SIZE = int((STEP_MS/1000.)/(1/FS)) # Window increment is one time-step\n",
    "CHAN_USE = np.arange(30) # There are 7 x 4 = 28 IMU channels and \n",
    "PRINT_SUMMARY = True # Print dimensions of aggregated data from all files\n",
    "\n",
    "arginput = [TRAIN_SIZE,PRED_SIZE,STEP_SIZE,CHAN_USE,PRINT_SUMMARY]\n",
    "\n",
    "alldict = unpack_files(filedict,allindtrigsdict,filekeys,arginput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select channels/features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define channels and trials\n",
    "LThigh = list(range(7))\n",
    "RThigh = list(range(8,15))\n",
    "LShank = list(range(15,22))\n",
    "RShank = list(range(22,29))\n",
    "Lcam = [29]\n",
    "Rcam = [30]\n",
    "\n",
    "LW_trials = list(range(14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select channels\n",
    "USE_CHAN = RThigh \n",
    "USE_FEAT = []\n",
    "for chan in USE_CHAN:\n",
    "    USE_FEAT.append(list(range(chan,180,30)))\n",
    "USE_FEAT = np.sort(np.concatenate(USE_FEAT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-one-trial-out cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing on LW_001 ===\n",
      "GTRUTH: [154, 198, 239, 280]\n",
      "IMU PRED: [154, 198, 240, 281]\n",
      "CAM PRED: [195, 235, 277]\n",
      "FUSE PRED: [155, 198, 240, 281]\n",
      "GTRUTH: [160, 203, 242, 285]\n",
      "IMU PRED: [158, 201, 242, 284, 328]\n",
      "CAM PRED: [154, 200, 238, 279, 313]\n",
      "FUSE PRED: [159, 202, 242, 285, 328]\n",
      "=== Testing on LW_002 ===\n",
      "GTRUTH: [194, 237, 281, 325]\n",
      "IMU PRED: [147, 193, 237, 282, 325]\n",
      "CAM PRED: [192, 237, 283, 328]\n",
      "FUSE PRED: [192, 236, 281, 325]\n",
      "GTRUTH: [199, 242, 286, 329]\n",
      "IMU PRED: [197, 241, 285, 329]\n",
      "CAM PRED: [198, 241, 286, 329]\n",
      "FUSE PRED: [197, 241, 285, 329]\n",
      "=== Testing on LW_003 ===\n",
      "GTRUTH: [136, 170]\n",
      "IMU PRED: [136, 170, 176]\n",
      "CAM PRED: [135, 169]\n",
      "FUSE PRED: [135, 170, 176]\n",
      "GTRUTH: [103, 139, 171]\n",
      "IMU PRED: [102, 137, 173]\n",
      "CAM PRED: [106, 141, 176]\n",
      "FUSE PRED: [102, 137, 172]\n",
      "=== Testing on LW_004 ===\n",
      "GTRUTH: [72, 107, 141]\n",
      "IMU PRED: [72, 106, 141]\n",
      "CAM PRED: [65, 100, 137]\n",
      "FUSE PRED: [72, 107, 142]\n",
      "GTRUTH: [74, 109]\n",
      "IMU PRED: [74, 109]\n",
      "CAM PRED: [73, 107]\n",
      "FUSE PRED: [74, 109]\n",
      "=== Testing on LW_005 ===\n",
      "GTRUTH: [148, 204, 258, 314, 366]\n",
      "IMU PRED: [139, 196, 252, 306, 362]\n",
      "CAM PRED: [148, 212, 260, 315]\n",
      "FUSE PRED: [141, 206, 255, 310, 366]\n",
      "GTRUTH: [156, 212, 264, 320]\n",
      "IMU PRED: [159, 212, 231, 266, 320]\n",
      "CAM PRED: [162, 218, 264, 320]\n",
      "FUSE PRED: [158, 211, 231, 266, 320, 339]\n",
      "=== Testing on LW_006 ===\n",
      "GTRUTH: [115, 171, 224, 275, 326]\n",
      "IMU PRED: [109, 172, 224, 276, 328]\n",
      "CAM PRED: [111, 168, 223, 277, 332]\n",
      "FUSE PRED: [107, 168, 220, 275, 328]\n",
      "GTRUTH: [125, 179, 230, 281]\n",
      "IMU PRED: [124, 178, 230, 282]\n",
      "CAM PRED: [122, 178, 229, 283]\n",
      "FUSE PRED: [125, 178, 230, 282, 301]\n",
      "=== Testing on LW_obstructed_001 ===\n",
      "GTRUTH: [126, 168, 209, 252, 297]\n",
      "IMU PRED: [126, 169, 209, 252, 295]\n",
      "CAM PRED: [118, 162, 205, 250]\n",
      "FUSE PRED: [209, 252]\n",
      "GTRUTH: [130, 171, 215, 257]\n",
      "IMU PRED: [129, 172, 213, 256]\n",
      "CAM PRED: [127, 168, 209, 254, 286]\n",
      "FUSE PRED: [130, 172, 214, 256, 260]\n",
      "=== Testing on LW_obstructed_002 ===\n",
      "GTRUTH: [138, 176, 213, 254, 295]\n",
      "IMU PRED: [137, 176, 213, 253, 294]\n",
      "CAM PRED: [135, 176, 215, 256]\n",
      "FUSE PRED: [137, 175, 182, 213, 253, 301]\n",
      "GTRUTH: [141, 179, 216, 257]\n",
      "IMU PRED: [140, 178, 216, 257]\n",
      "CAM PRED: [143, 180, 220, 259, 288]\n",
      "FUSE PRED: [140, 177, 216, 256]\n",
      "=== Testing on LW_obstructed_003 ===\n",
      "GTRUTH: [166, 205, 247, 289]\n",
      "IMU PRED: [167, 205, 247, 289]\n",
      "CAM PRED: [166, 207, 251, 297]\n",
      "FUSE PRED: [166, 205, 248, 290]\n",
      "GTRUTH: [129, 170, 208, 251]\n",
      "IMU PRED: [128, 170, 211, 252]\n",
      "CAM PRED: [129, 171, 213, 257]\n",
      "FUSE PRED: [128, 170, 210, 251]\n",
      "=== Testing on LW_obstructed_004 ===\n",
      "GTRUTH: [160, 199, 238, 277]\n",
      "IMU PRED: [160, 166, 198, 236, 277]\n",
      "CAM PRED: [157, 196, 238, 278]\n",
      "FUSE PRED: [119, 160, 197, 236, 277, 283]\n",
      "GTRUTH: [163, 203, 242, 281]\n",
      "IMU PRED: [162, 201, 241, 280]\n",
      "CAM PRED: [161, 200, 241, 279, 299]\n",
      "FUSE PRED: [162, 201, 241, 280, 289]\n",
      "=== Testing on LW_obstructed_005 ===\n",
      "GTRUTH: [107, 149, 189, 230, 271]\n",
      "IMU PRED: [106, 149, 190, 231, 272]\n",
      "CAM PRED: [144, 187, 272]\n",
      "FUSE PRED: [149, 190, 272]\n",
      "GTRUTH: [113, 152, 192, 233]\n",
      "IMU PRED: [113, 152, 196, 234]\n",
      "CAM PRED: [109, 150, 193, 234, 274]\n",
      "FUSE PRED: [113, 153, 196, 234]\n",
      "=== Testing on LW_obstructed_turn_001 ===\n",
      "GTRUTH: [102, 139, 175]\n",
      "IMU PRED: [103, 108, 139, 176]\n",
      "CAM PRED: [96, 135, 172]\n",
      "FUSE PRED: [139, 176]\n",
      "GTRUTH: [69, 105, 142, 178]\n",
      "IMU PRED: [68, 105, 141, 177, 209]\n",
      "CAM PRED: [66, 105, 141, 177, 213]\n",
      "FUSE PRED: [62, 68, 105, 135, 141, 177, 209]\n",
      "=== Testing on LW_obstructed_turn_002 ===\n",
      "GTRUTH: [96, 132, 169]\n",
      "IMU PRED: [94, 131, 168]\n",
      "CAM PRED: [91, 129, 167]\n",
      "FUSE PRED: [94, 132, 168]\n",
      "GTRUTH: [61, 99, 135, 173]\n",
      "IMU PRED: [61, 98, 135, 172]\n",
      "CAM PRED: [62, 98, 136, 173]\n",
      "FUSE PRED: [61, 86, 98, 135, 172]\n",
      "=== Testing on LW_obstructed_turn_004 ===\n",
      "GTRUTH: [167, 208, 247, 287, 326]\n",
      "IMU PRED: [167, 207, 247, 286, 326]\n",
      "CAM PRED: [164, 245, 288, 329]\n",
      "FUSE PRED: [167, 208, 212, 247, 286, 326]\n",
      "GTRUTH: [170, 211, 249, 292, 329]\n",
      "IMU PRED: [171, 211, 252, 290, 330]\n",
      "CAM PRED: [170, 211, 250, 291, 331, 370]\n",
      "FUSE PRED: [171, 211, 253, 290, 330]\n"
     ]
    }
   ],
   "source": [
    "all_lhc_resid, all_lcam_resid, all_lfuse_resid = [], [], []\n",
    "all_lhc_f1, all_lhc_f1_cam, all_lhc_f1_fused = [], [], []\n",
    "all_rto_resid, all_rcam_resid, all_rfuse_resid = [], [], []\n",
    "all_rto_f1, all_rto_f1_cam, all_rto_f1_fused = [], [], []\n",
    "\n",
    "for testtrial in LW_trials:\n",
    "# for testtrial in [7]:\n",
    "    RTO_templates, LHC_templates, testwin_Rcam, testwin_Lcam, IMU_prob, Lcamprob, Lcambinwin, Rcamprob, Rcambinwin, trueL, trueR = segmentation(alldict,filedict,filekeys,allindtrigsdict,LW_trials,[testtrial],150,USE_FEAT,25)    \n",
    "#     IMU_prob = [LR_Lprob, RF_Lprob, LDA_Lprob, SVM_Lprob, LR_Rprob, RF_Rprob, LDA_Rprob, SVM_Rprob]\n",
    "\n",
    "    LDA_Lprob = IMU_prob[2]\n",
    "    LDA_Rprob = IMU_prob[6]\n",
    "    \n",
    "    LDA_Lbin = np.array([np.argmax(LDA_Lprob[i]) for i in range(LDA_Lprob.shape[0])])\n",
    "    LDA_Rbin = np.array([np.argmax(LDA_Rprob[i]) for i in range(LDA_Rprob.shape[0])])\n",
    "    \n",
    "    Lcamprob = np.array(Lcamprob)\n",
    "    CAM_LHCbin = np.array([Lcamprob[i] > 0.55 for i in range(len(Lcamprob))])*1\n",
    "    FUSE_LHCbin = np.array([(0.5*LDA_Lprob[i,1] + 0.5*Lcamprob[i]) > 0.55 for i in range(LDA_Lprob.shape[0])])*1\n",
    "    \n",
    "    Rcamprob = np.array(Rcamprob)    \n",
    "    CAM_RTObin = np.array([Rcamprob[i] > 0.55 for i in range(len(Rcamprob))])*1\n",
    "    FUSE_RTObin = np.array([(0.5*LDA_Rprob[i,0] + 0.5*Rcamprob[i]) > 0.55 for i in range(LDA_Rprob.shape[0])])*1\n",
    "\n",
    "    lhc_resid, cam_lhc_resid, fuse_lhc_resid, lhc_f1, lhc_f1_cam, lhc_f1_fused = calc_resids(trueL.ravel(),LDA_Lbin,CAM_LHCbin.ravel(),FUSE_LHCbin.ravel(),'LHC',STEP_MS)\n",
    "    rto_resid, cam_rto_resid, fuse_rto_resid, rto_f1, rto_f1_cam, rto_f1_fused = calc_resids(trueR.ravel(),LDA_Rbin,CAM_RTObin.ravel(),FUSE_RTObin.ravel(),'RTO',STEP_MS)\n",
    "    \n",
    "    all_lhc_resid.append(lhc_resid)\n",
    "    all_rto_resid.append(rto_resid)\n",
    "    all_lhc_f1.append(lhc_f1)\n",
    "    all_rto_f1.append(rto_f1)\n",
    "    \n",
    "    all_lcam_resid.append(cam_lhc_resid)\n",
    "    all_rcam_resid.append(cam_rto_resid)\n",
    "    all_lhc_f1_cam.append(lhc_f1_cam)\n",
    "    all_rto_f1_cam.append(rto_f1_cam)\n",
    "    \n",
    "    all_lfuse_resid.append(fuse_lhc_resid)\n",
    "    all_rfuse_resid.append(fuse_rto_resid)\n",
    "    all_lhc_f1_fused.append(lhc_f1_fused)\n",
    "    all_rto_f1_fused.append(rto_f1_fused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIMU F1: 0.880733944954\n",
      "RCAM F1: 0.880733944954\n",
      "RFUSED F1: 0.915254237288\n",
      "LIMU F1: 0.920353982301\n",
      "LCAM F1: 0.848484848485\n",
      "LFUSED F1: 0.872727272727\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 scores for each sensor modality (averaged across all trials)\n",
    "all_rto_f1 = np.array(all_rto_f1)\n",
    "all_rto_f1_cam = np.array(all_rto_f1_cam)\n",
    "all_rto_f1_fused = np.array(all_rto_f1_fused)\n",
    "\n",
    "avg_rto_f1_imu = 2*np.sum(all_rto_f1[:,0])/(2*np.sum(all_rto_f1[:,0]) + np.sum(all_rto_f1[:,1]) + np.sum(all_rto_f1[:,2]))\n",
    "avg_rto_f1_cam = 2*np.sum(all_rto_f1_cam[:,0])/(2*np.sum(all_rto_f1_cam[:,0]) + np.sum(all_rto_f1_cam[:,1]) + np.sum(all_rto_f1_cam[:,2]))\n",
    "avg_rto_f1_fused = 2*np.sum(all_rto_f1_fused[:,0])/(2*np.sum(all_rto_f1_fused[:,0]) + np.sum(all_rto_f1_fused[:,1]) + np.sum(all_rto_f1_fused[:,2]))\n",
    "\n",
    "print('RIMU F1: {}'.format(avg_rto_f1_imu))\n",
    "print('RCAM F1: {}'.format(avg_rto_f1_cam))\n",
    "print('RFUSED F1: {}'.format(avg_rto_f1_fused))\n",
    "\n",
    "all_lhc_f1 = np.array(all_lhc_f1)\n",
    "all_lhc_f1_cam = np.array(all_lhc_f1_cam)\n",
    "all_lhc_f1_fused = np.array(all_lhc_f1_fused)\n",
    "\n",
    "avg_lhc_f1_imu = 2*np.sum(all_lhc_f1[:,0])/(2*np.sum(all_lhc_f1[:,0]) + np.sum(all_lhc_f1[:,1]) + np.sum(all_lhc_f1[:,2]))\n",
    "avg_lhc_f1_cam = 2*np.sum(all_lhc_f1_cam[:,0])/(2*np.sum(all_lhc_f1_cam[:,0]) + np.sum(all_lhc_f1_cam[:,1]) + np.sum(all_lhc_f1_cam[:,2]))\n",
    "avg_lhc_f1_fused = 2*np.sum(all_lhc_f1_fused[:,0])/(2*np.sum(all_lhc_f1_fused[:,0]) + np.sum(all_lhc_f1_fused[:,1]) + np.sum(all_lhc_f1_fused[:,2]))\n",
    "\n",
    "print('LIMU F1: {}'.format(avg_lhc_f1_imu))\n",
    "print('LCAM F1: {}'.format(avg_lhc_f1_cam))\n",
    "print('LFUSED F1: {}'.format(avg_lhc_f1_fused))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show features, feature templates, and estimated probability-  use filekey 0 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use filekey 0\n",
    "Lwindownum = 192\n",
    "Rwindownum = 150\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(filedict[filekeys[0]][1],color='g')\n",
    "plt.plot(filedict[filekeys[0]][5],color='k')\n",
    "plt.plot()\n",
    "plt.title('LCAM',y=1.08)\n",
    "plt.yticks(np.arange(-1.5,2,0.5), ('-1.5', '-1', '-0.5', '0', '0.5', '1', '1.5'))\n",
    "plt.xlabel('Samples',fontweight = 'bold')\n",
    "plt.ylabel('Shank angle (rad)',fontweight = 'bold')\n",
    "# plt.savefig('Shankangle.png', dpi=300)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(filedict[filekeys[0]][2],color='g')\n",
    "plt.plot(filedict[filekeys[0]][6],color='k')\n",
    "plt.title('RCAM',y=1.08)\n",
    "plt.yticks(np.arange(-1.5,2,0.5), ('-1.5', '-1', '-0.5', '0', '0.5', '1', '1.5'))\n",
    "plt.xlabel('Samples',fontweight = 'bold')\n",
    "plt.ylabel('Ground angle (rad)',fontweight = 'bold')\n",
    "# plt.savefig('Groundangle.png', dpi=300)\n",
    "\n",
    "plt.figure()\n",
    "for temp in range(len(LHC_templates)):\n",
    "    plt.plot(LHC_templates[temp],color='k',alpha=0.15)\n",
    "avg_LHC_template = sum(LHC_templates)/len(LHC_templates)\n",
    "plt.plot(avg_LHC_template,color='g',linewidth=4.5)\n",
    "plt.title('LCAM Template',y=1.08)\n",
    "plt.xticks(np.arange(0,200,50), ('-150', '-100', '-50', 'LHC'))\n",
    "plt.yticks(np.arange(-1.5,2,0.5), ('-1.5', '-1', '-0.5', '0', '0.5', '1', '1.5'))\n",
    "plt.xlabel('Samples',fontweight = 'bold')\n",
    "plt.ylabel('Shank angle (rad)',fontweight = 'bold')\n",
    "# plt.savefig('Shankangle_temp.png', dpi=300)\n",
    "\n",
    "plt.figure()\n",
    "for temp in range(len(RTO_templates)):\n",
    "    plt.plot(RTO_templates[temp],color='k',alpha=0.15)\n",
    "avg_RTO_template = sum(RTO_templates)/len(RTO_templates)\n",
    "plt.plot(avg_RTO_template,color='g',linewidth=4.5)\n",
    "plt.title('RCAM Template',y=1.08)\n",
    "plt.xticks(np.arange(0,200,50), ('-150', '-100', '-50', 'RTO'))\n",
    "plt.yticks(np.arange(-1.5,2,0.5), ('-1.5', '-1', '-0.5', '0', '0.5', '1', '1.5'))\n",
    "plt.xlabel('Samples',fontweight = 'bold')\n",
    "plt.ylabel('Ground angle (rad)',fontweight = 'bold')\n",
    "# plt.savefig('Groundangle_temp.png', dpi=300)\n",
    "\n",
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(111)\n",
    "ax2.plot(avg_LHC_template,color='g',linewidth=4.5)\n",
    "ax2.plot(testwin_Lcam[Lwindownum],color='g',alpha=0.6,linewidth=3,linestyle='--')\n",
    "ax2.fill_between(np.arange(150), -1.5, 1.5, where= Lcambinwin[Lwindownum] > 0.5, facecolor='green', alpha=0.15)\n",
    "plt.title('LCAM Matching Probability',y=1.08)\n",
    "plt.xticks(np.arange(0,200,50), ('-150', '-100', '-50', 'LHC'))\n",
    "plt.yticks(np.arange(-1.5,2,0.5), ('-1.5', '-1', '-0.5', '0', '0.5', '1', '1.5'))\n",
    "plt.xlabel('Samples',fontweight = 'bold')\n",
    "plt.ylabel('Shank angle (rad)',fontweight = 'bold')\n",
    "# plt.savefig('Shankangle_conv.png', dpi=300)\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(111)\n",
    "ax1.plot(avg_RTO_template,color='g',linewidth=4.5)\n",
    "ax1.plot(testwin_Rcam[Rwindownum],color='g',alpha=0.6,linewidth=3,linestyle='--')\n",
    "ax1.fill_between(np.arange(150), -1.5, 1.5, where= Rcambinwin[Rwindownum] > 0.5, facecolor='green', alpha=0.15)\n",
    "plt.title('RCAM Matching Probability',y=1.08)\n",
    "plt.xticks(np.arange(0,200,50), ('-150', '-100', '-50', 'RTO'))\n",
    "plt.yticks(np.arange(-1.5,2,0.5), ('-1.5', '-1', '-0.5', '0', '0.5', '1', '1.5'))\n",
    "plt.xlabel('Samples',fontweight = 'bold')\n",
    "plt.ylabel('Ground angle (rad)',fontweight = 'bold')\n",
    "# plt.savefig('Groundangle_conv.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show probability estimates and event detection (IMU, CAM, FUSED)- use filekey 7 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use filekey 7\n",
    "lhc_start = 100\n",
    "lhc_end = 250\n",
    "\n",
    "fig4 = plt.figure(figsize=(5,3))\n",
    "ax4 = fig4.add_subplot(111)\n",
    "ax4.plot(LDA_Lprob[lhc_start:lhc_end,1],color='b')\n",
    "ax4.plot(trueL[lhc_start:lhc_end],color='k')\n",
    "ax4.fill_between(np.arange(150), 0, 1, where= LDA_Lprob[lhc_start:lhc_end,1] > 0.5, facecolor='b', alpha=0.15)\n",
    "plt.title('LIMU', y=1.08)\n",
    "plt.xticks(np.arange(0,200,50), ('0', '50', '100', '150'))\n",
    "plt.yticks(np.arange(0,1.5,0.5), ('0', '0.5', '1'))\n",
    "plt.xlabel('Samples',fontweight = 'bold')\n",
    "plt.ylabel('Probability',fontweight = 'bold')\n",
    "# plt.savefig('LIMUdetect.png', dpi=300)\n",
    "\n",
    "fig3 = plt.figure(figsize=(5,3))\n",
    "ax3 = fig3.add_subplot(111)\n",
    "ax3.plot(Lcamprob[lhc_start:lhc_end],color='g')\n",
    "ax3.plot(trueL[lhc_start:lhc_end],color='k')\n",
    "ax3.fill_between(np.arange(150), 0, 1, where= Lcamprob[lhc_start:lhc_end] > 0.55, facecolor='g', alpha=0.15)\n",
    "plt.title('LDEPTH', y=1.08)\n",
    "plt.xticks(np.arange(0,200,50), ('0', '50', '100', '150'))\n",
    "plt.yticks(np.arange(0,1.5,0.5), ('0', '0.5', '1'))\n",
    "plt.xlabel('Samples',fontweight = 'bold')\n",
    "plt.ylabel('Probability',fontweight = 'bold')\n",
    "# plt.savefig('LCAMdetect.png', dpi=300)\n",
    "\n",
    "fig5 = plt.figure(figsize=(5,3))\n",
    "ax5 = fig5.add_subplot(111)\n",
    "ax5.plot(0.5*LDA_Lprob[lhc_start:lhc_end,1] + 0.5*Lcamprob[lhc_start:lhc_end],color='r')\n",
    "ax5.plot(trueL[lhc_start:lhc_end],color='k')\n",
    "ax5.fill_between(np.arange(150), 0, 1, where= (0.5*LDA_Lprob[lhc_start:lhc_end,1] + 0.5*Lcamprob[lhc_start:lhc_end]) > 0.55, facecolor='r', alpha=0.15)\n",
    "plt.title('LFUSE', y=1.08)\n",
    "plt.xticks(np.arange(0,200,50), ('0', '50', '100', '150'))\n",
    "plt.yticks(np.arange(0,1.5,0.5), ('0', '0.5', '1'))\n",
    "plt.xlabel('Samples',fontweight = 'bold')\n",
    "plt.ylabel('Probability',fontweight = 'bold')\n",
    "# plt.savefig('LFUSEDdetect.png', dpi=300)\n",
    "\n",
    "rto_start = 100\n",
    "rto_end = 250\n",
    "\n",
    "fig7 = plt.figure(figsize=(5,3))\n",
    "ax7 = fig7.add_subplot(111)\n",
    "ax7.plot(LDA_Rprob[rto_start:rto_end,1],color='b')\n",
    "ax7.plot(trueR[rto_start:rto_end],color='k')\n",
    "ax7.fill_between(np.arange(150), 0, 1, where= LDA_Rprob[rto_start:rto_end,1] < 0.55, facecolor='b', alpha=0.15)\n",
    "plt.title('RIMU', y=1.08)\n",
    "plt.xticks(np.arange(0,200,50), ('0', '50', '100', '150'))\n",
    "plt.yticks(np.arange(0,1.5,0.5), ('0', '0.5', '1'))\n",
    "plt.xlabel('Samples',fontweight = 'bold')\n",
    "plt.ylabel('Probability',fontweight = 'bold')\n",
    "# plt.savefig('RIMUdetect.png', dpi=300)\n",
    "\n",
    "fig6 = plt.figure(figsize=(5,3))\n",
    "ax6 = fig6.add_subplot(111)\n",
    "ax6.plot(Rcamprob[rto_start:rto_end],color='g')\n",
    "ax6.plot(trueR[rto_start:rto_end],color='k')\n",
    "ax6.fill_between(np.arange(150), 0, 1, where= Rcamprob[rto_start:rto_end] > 0.55, facecolor='g', alpha=0.15)\n",
    "plt.title('RDEPTH', y=1.08)\n",
    "plt.xticks(np.arange(0,200,50), ('0', '50', '100', '150'))\n",
    "plt.yticks(np.arange(0,1.5,0.5), ('0', '0.5', '1'))\n",
    "plt.xlabel('Samples',fontweight = 'bold')\n",
    "plt.ylabel('Probability',fontweight = 'bold')\n",
    "# plt.savefig('RCAMdetect.png', dpi=300)\n",
    "\n",
    "fig8 = plt.figure(figsize=(5,3))\n",
    "ax8 = fig8.add_subplot(111)\n",
    "ax8.plot(0.5*LDA_Rprob[rto_start:rto_end,0] + 0.5*Rcamprob[rto_start:rto_end],color='r')\n",
    "ax8.plot(trueR[rto_start:rto_end],color='k')\n",
    "ax8.fill_between(np.arange(150), 0, 1, where= (0.5*LDA_Rprob[rto_start:rto_end,0] + 0.5*Rcamprob[rto_start:rto_end]) > 0.55, facecolor='r', alpha=0.15)\n",
    "plt.title('RFUSE', y=1.08)\n",
    "plt.xticks(np.arange(0,200,50), ('0', '50', '100', '150'))\n",
    "plt.yticks(np.arange(0,1.5,0.5), ('0', '0.5', '1'))\n",
    "plt.xlabel('Samples',fontweight = 'bold')\n",
    "plt.ylabel('Probability',fontweight = 'bold')\n",
    "# plt.savefig('RFUSEDdetect.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make figures for St/Sw classifier and sliding windows for IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwins = alldict['Combined'][0]\n",
    "allfeats = alldict['Combined'][1]\n",
    "allLtruth = alldict['Combined'][2]\n",
    "allRtruth = alldict['Combined'][3]\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "pca = PCA(n_components = 25)\n",
    "\n",
    "allfeats_scale = scaler.fit(allfeats).transform(allfeats)\n",
    "allfeats_pca = pca.fit(allfeats_scale).transform(allfeats_scale)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i in range(np.shape(allfeats_pca)[0]):\n",
    "    if allLtruth[i] == 0:\n",
    "        ax.scatter(allfeats_pca[i,0], allfeats_pca[i,1], allfeats_pca[i,2], color = 'k', s = 16)\n",
    "    else:\n",
    "        ax.scatter(allfeats_pca[i,0], allfeats_pca[i,1], allfeats_pca[i,2], facecolors='w', edgecolors= (70/255.,70/255.,70/255.), s = 16)\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.set_xlabel('PCA1',fontweight='bold',labelpad=20)        \n",
    "ax.set_ylabel('PCA2',fontweight='bold',labelpad=20)\n",
    "ax.set_zlabel('PCA3',fontweight='bold',labelpad=20)\n",
    "\n",
    "# IMU acc. representative window\n",
    "plt.figure()\n",
    "plt.plot(allwins[150,:,0])\n",
    "plt.plot(allwins[150,:,1])\n",
    "plt.plot(allwins[150,:,2])\n",
    "plt.xticks(np.arange(0,200,50), ('0', '50', '100', '150'))\n",
    "plt.xlabel('Samples',fontweight = 'bold')\n",
    "plt.ylabel('Acc (g)',fontweight = 'bold')\n",
    "\n",
    "# IMU gyro representative window\n",
    "plt.figure()\n",
    "plt.plot(allwins[150,:,3])\n",
    "plt.plot(allwins[150,:,4])\n",
    "plt.plot(allwins[150,:,5])\n",
    "plt.xticks(np.arange(0,200,50), ('0', '50', '100', '150'))\n",
    "plt.xlabel('Samples',fontweight = 'bold')\n",
    "plt.ylabel('Gyro (deg/s)',fontweight = 'bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize residuals and make histogram plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lhc_resid = np.concatenate(all_lhc_resid)\n",
    "all_rto_resid = np.concatenate(all_rto_resid)\n",
    "all_lcam_resid = np.concatenate(all_lcam_resid)\n",
    "all_rcam_resid = np.concatenate(all_rcam_resid)\n",
    "all_lfuse_resid = np.concatenate(all_lfuse_resid)\n",
    "all_rfuse_resid = np.concatenate(all_rfuse_resid)\n",
    "\n",
    "all_lhc_resid_inrange = [i for i in all_lhc_resid if abs(i) < 400]\n",
    "all_rto_resid_inrange = [i for i in all_rto_resid if abs(i) < 600]\n",
    "all_lcam_resid_inrange = [i for i in all_lcam_resid if abs(i) < 400]\n",
    "all_rcam_resid_inrange = [i for i in all_rcam_resid if abs(i) < 600]\n",
    "all_lfuse_resid_inrange = [i for i in all_lfuse_resid if abs(i) < 400]\n",
    "all_rfuse_resid_inrange = [i for i in all_rfuse_resid if abs(i) < 600]\n",
    "\n",
    "all_lhc_resid_outrange = [i for i in all_lhc_resid if abs(i) > 400]\n",
    "all_rto_resid_outrange = [i for i in all_rto_resid if abs(i) > 600]\n",
    "all_lcam_resid_outrange = [i for i in all_lcam_resid if abs(i) > 400]\n",
    "all_rcam_resid_outrange = [i for i in all_rcam_resid if abs(i) > 600]\n",
    "all_lfuse_resid_outrange = [i for i in all_lfuse_resid if abs(i) > 400]\n",
    "all_rfuse_resid_outrange = [i for i in all_rfuse_resid if abs(i) > 600]\n",
    "\n",
    "print('LHC outlier: {} / LCAM outlier: {} / LFUSE outlier: {}'.format(len(all_lhc_resid_outrange), len(all_lcam_resid_outrange), len(all_lfuse_resid_outrange)))\n",
    "print('RTO outlier: {} / RCAM outlier: {} / RFUSE outlier: {}'.format(len(all_rto_resid_outrange), len(all_rcam_resid_outrange), len(all_rfuse_resid_outrange)))\n",
    "\n",
    "print('LHC mean/sd: {}/{}'.format(np.mean(all_lhc_resid_inrange),np.std(all_lhc_resid_inrange)))\n",
    "print('CAM LHC mean/sd: {}/{}'.format(np.mean(all_lcam_resid_inrange),np.std(all_lcam_resid_inrange)))\n",
    "print('FUSE LHC mean/sd: {}/{}'.format(np.mean(all_lfuse_resid_inrange),np.std(all_lfuse_resid_inrange)))\n",
    "\n",
    "print('RTO mean/sd: {}/{}'.format(np.mean(all_rto_resid_inrange),np.std(all_rto_resid_inrange)))\n",
    "print('CAM RTO mean/sd: {}/{}'.format(np.mean(all_rcam_resid_inrange),np.std(all_rcam_resid_inrange)))\n",
    "print('FUSE RTO mean/sd: {}/{}'.format(np.mean(all_rfuse_resid_inrange),np.std(all_rfuse_resid_inrange)))\n",
    "\n",
    "all_resid = {'LHC': all_lhc_resid, 'RTO': all_rto_resid, 'LCAM': all_lcam_resid, 'RCAM': all_rcam_resid, 'LFUSE': all_lfuse_resid, 'RFUSE': all_rfuse_resid}\n",
    "# sio.savemat('allresiduals_allIMU_RF.mat',all_resid)\n",
    "\n",
    "lhc_wts = np.ones_like(all_lhc_resid_inrange)/float(len(all_lhc_resid_inrange))\n",
    "lcam_wts = np.ones_like(all_lcam_resid_inrange)/float(len(all_lcam_resid_inrange))\n",
    "lfuse_wts = np.ones_like(all_lfuse_resid_inrange)/float(len(all_lfuse_resid_inrange))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(all_lhc_resid_inrange,range(-315,315,30),color='b',alpha=0.6,weights=lhc_wts)\n",
    "plt.title('LIMU',y=1.08)\n",
    "plt.xticks(range(-300,400,100))\n",
    "plt.yticks(np.arange(0,0.6,0.1), ('0', '0.1', '0.2', '0.3', '0.4', '0.5'))\n",
    "plt.xlabel('Time (ms)',fontweight = 'bold')\n",
    "plt.ylabel('Relative frequency',fontweight = 'bold')\n",
    "plt.savefig('LIMU.png', dpi=300)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(all_lcam_resid_inrange,range(-315,315,30),color='g',alpha=0.6,weights=lcam_wts)\n",
    "plt.title('LDEPTH',y=1.08)\n",
    "plt.xticks(range(-300,400,100))\n",
    "plt.yticks(np.arange(0,0.6,0.1), ('0', '0.1', '0.2', '0.3', '0.4', '0.5'))\n",
    "plt.xlabel('Time (ms)',fontweight = 'bold')\n",
    "plt.ylabel('Relative frequency',fontweight = 'bold')\n",
    "plt.savefig('LCAM.png', dpi=300)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(all_lfuse_resid_inrange,range(-315,315,30),color='r',alpha=0.6,weights=lfuse_wts)\n",
    "plt.title('LFUSE',y=1.08)\n",
    "plt.xticks(range(-300,400,100))\n",
    "plt.yticks(np.arange(0,0.6,0.1), ('0', '0.1', '0.2', '0.3', '0.4', '0.5'))\n",
    "plt.xlabel('Time (ms)',fontweight = 'bold')\n",
    "plt.ylabel('Relative frequency',fontweight = 'bold')\n",
    "plt.savefig('LFUSE.png', dpi=300)\n",
    "\n",
    "rto_wts = np.ones_like(all_rto_resid_inrange)/float(len(all_rto_resid_inrange))\n",
    "rcam_wts = np.ones_like(all_rcam_resid_inrange)/float(len(all_rcam_resid_inrange))\n",
    "rfuse_wts = np.ones_like(all_rfuse_resid_inrange)/float(len(all_rfuse_resid_inrange))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(all_rto_resid_inrange,range(-315,315,30),color='b',alpha=0.6,weights=rto_wts)\n",
    "plt.title('RIMU', y = 1.08)\n",
    "plt.xticks(range(-300,400,100))\n",
    "plt.yticks(np.arange(0,0.5,0.1), ('0', '0.1', '0.2', '0.3', '0.4'))\n",
    "plt.xlabel('Time (ms)',fontweight = 'bold')\n",
    "plt.ylabel('Relative frequency',fontweight = 'bold')\n",
    "plt.savefig('RIMU.png', dpi=300)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(all_rcam_resid_inrange,range(-315,315,30),color='g',alpha=0.6,weights=rcam_wts)\n",
    "plt.title('RDEPTH', y = 1.08)\n",
    "plt.xticks(range(-300,400,100))\n",
    "plt.yticks(np.arange(0,0.5,0.1), ('0', '0.1', '0.2', '0.3', '0.4'))\n",
    "plt.xlabel('Time (ms)',fontweight = 'bold')\n",
    "plt.ylabel('Relative frequency',fontweight = 'bold')\n",
    "plt.savefig('RCAM.png', dpi=300)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(all_rfuse_resid_inrange,range(-315,315,30),color='r',alpha=0.6,weights=rfuse_wts)\n",
    "plt.title('RFUSE', y = 1.08)\n",
    "plt.xticks(range(-300,400,100))\n",
    "plt.yticks(np.arange(0,0.5,0.1), ('0', '0.1', '0.2', '0.3', '0.4'))\n",
    "plt.xlabel('Time (ms)',fontweight = 'bold')\n",
    "plt.ylabel('Relative frequency',fontweight = 'bold')\n",
    "plt.savefig('RFUSE.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
